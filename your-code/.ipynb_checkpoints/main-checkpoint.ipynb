{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selenium Doc](https://www.selenium.dev/documentation/)\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `Selenium` and `pandas` are imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.common.by import By # By es para buscar por tag, clase, id...\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable the options you may need. In the next cell you have an example of them but you can choose to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver configuration\n",
    "opciones=Options()\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "#opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "#opciones.add_argument('user-data-dir=selenium')    # mantiene las cookies\n",
    "#opciones.add_extension('driver_folder/adblock.crx')       # adblocker\n",
    "opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = \"./chromedriver.exe\" #remember substitute this for your driver path\n",
    "#driver = webdriver.Chrome(driver,options = opciones)\n",
    "PATH = ChromeDriverManager().install()     # instala el driver de chrome\n",
    "\n",
    "driver=webdriver.Chrome(PATH, options = opciones)       # abre una venta una de chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse, and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ariel Mashraki',\n",
       " 'Mattias Wadman',\n",
       " 'Henrik Rydgård',\n",
       " 'Mark Tyneway',\n",
       " 'Lincoln Stein',\n",
       " 'jxxghp',\n",
       " 'Paul Razvan Berg',\n",
       " 'Florian Roth',\n",
       " 'MichaIng',\n",
       " 'Vectorized',\n",
       " 'Lianmin Zheng',\n",
       " 'X.',\n",
       " 'Norbert de Langen',\n",
       " 'Stefan Prodan',\n",
       " 'Jaco',\n",
       " 'François Chollet',\n",
       " 'Michał Lytek',\n",
       " 'Lukas Taegert-Atkinson',\n",
       " 'Ben McCann',\n",
       " 'Antonio Cheong',\n",
       " 'Maarten Grootendorst',\n",
       " 'Leon',\n",
       " 'syuilo',\n",
       " 'Abhinav Gupta',\n",
       " 'Yair Morgenstern']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [e.text for e in driver.find_elements(By.CLASS_NAME, \"h3.lh-condensed\")]\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH, options = opciones) \n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acheong08 / ChatGPT',\n",
       " 'Zero6992 / chatGPT-discord-bot',\n",
       " 'TheAlgorithms / Python',\n",
       " 'LAION-AI / Open-Assistant',\n",
       " 'ddPn08 / Lsmith',\n",
       " 'zhayujie / chatgpt-on-wechat',\n",
       " 'LeagueOfPoro / CapsuleFarmerEvolved',\n",
       " 'microsoft / BioGPT',\n",
       " 'BlinkDL / ChatRWKV',\n",
       " 'AIGCT / EASYChatGPT',\n",
       " 'mmz-001 / knowledge_gpt',\n",
       " 'jxxghp / nas-tools',\n",
       " 'tiangolo / fastapi',\n",
       " 'TomSchimansky / CustomTkinter',\n",
       " 'Rudrabha / Wav2Lip',\n",
       " 'public-apis / public-apis',\n",
       " 'biancangming / wtv',\n",
       " 'chidiwilliams / buzz',\n",
       " 'bellingcat / octosuite',\n",
       " 'approximatelabs / sketch',\n",
       " 'yerfor / GeneFace',\n",
       " 'uptrain-ai / uptrain',\n",
       " 'facebookresearch / metaseq',\n",
       " 'lss233 / chatgpt-mirai-qq-bot',\n",
       " 'ansible / ansible']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos = [e.text for e in driver.find_elements(By.CLASS_NAME, \"h3.lh-condensed\")]\n",
    "\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/static/images/icons/wikipedia.png',\n",
       " 'https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg',\n",
       " 'https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-en.svg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/38px-Wikisource-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/34px-Wikiquote-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/15px-Magic_Kingdom_castle.jpg',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/14px-Commons-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/18px-Wikisource-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/21px-Wikidata-logo.svg.png',\n",
       " 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://en.wikipedia.org/static/images/footer/wikimedia-button.png',\n",
       " 'https://en.wikipedia.org/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.get_attribute('src') for e in driver.find_elements(By.TAG_NAME, \"img\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# He intentado hacerlo sobre esta otra url, pero el kernel falla al iterar tantos elementos.\n",
    "\n",
    "#driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/ul[2]/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Python#bodyContent'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_a = driver.find_elements(By.TAG_NAME, 'a')\n",
    "driver.find_elements(By.TAG_NAME, 'a')[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Python#bodyContent',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Special:Search',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " 'https://en.wikipedia.org/wiki/Help:Introduction',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyTalk',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyContributions',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "for i in range(len(all_a)):\n",
    "    links.append(driver.find_elements(By.TAG_NAME, 'a')[i].get_attribute('href'))\n",
    "    \n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [driver.find_elements(By.TAG_NAME, 'a')[i].get_attribute('href') for i in range(len(driver.find_elements(By.TAG_NAME, 'a')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Python#bodyContent',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Special:Search',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " 'https://en.wikipedia.org/wiki/Help:Introduction',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyTalk',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyContributions',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title 6 - Domestic Security'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CLASS_NAME, \"usctitlechanged\")[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [e.text for e in driver.find_elements(By.CLASS_NAME, \"usctitlechanged\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUJA IGNATOVA'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '//h3[@class=\"title\"]')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUJA IGNATOVA'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CLASS_NAME, 'title')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "topten = [e.text for e in driver.find_elements(By.CLASS_NAME, \"title\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'RUJA IGNATOVA',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'OMAR ALEXANDER CARDENAS',\n",
       " 'ALEXIS FLORES',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'MICHAEL JAMES PRATT',\n",
       " 'RAFAEL CARO-QUINTERO']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topten[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [e.text for e in driver.find_elements(By.TAG_NAME, 'th')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = [e.text for e in driver.find_elements(By.TAG_NAME, 'tr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = filas[14:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-02-08   17:12:52.5\\n10min ago\\n38.09  N   37.40  E   10 2.7  CENTRAL TURKEY',\n",
       " 'F\\n2023-02-08   17:06:39.4\\n16min ago\\n38.87  N   37.38  E   2 3.6  CENTRAL TURKEY',\n",
       " '2023-02-08   17:03:58.4\\n19min ago\\n37.87  N   36.72  E   8 2.9  CENTRAL TURKEY',\n",
       " '2023-02-08   17:02:32.3\\n20min ago\\n35.47  N   3.66  W   4 2.4  STRAIT OF GIBRALTAR',\n",
       " '2023-02-08   17:01:12.6\\n21min ago\\n38.09  N   37.17  E   8 3.1  CENTRAL TURKEY',\n",
       " '1\\nII\\n2023-02-08   16:59:20.0\\n23min ago\\n37.10  N   36.74  E   11 3.5  CENTRAL TURKEY',\n",
       " '8\\nIII\\n2023-02-08   16:55:39.5\\n27min ago\\n38.10  N   37.20  E   2 4.2  CENTRAL TURKEY',\n",
       " '2023-02-08   16:44:28.2\\n38min ago\\n37.97  N   38.25  E   5 2.7  EASTERN TURKEY',\n",
       " 'F\\n2023-02-08   16:40:33.2\\n42min ago\\n37.84  N   36.60  E   16 3.2  CENTRAL TURKEY',\n",
       " '1\\nF\\n2023-02-08   16:29:07.4\\n54min ago\\n37.74  N   37.40  E   17 2.7  CENTRAL TURKEY',\n",
       " '2023-02-08   16:21:19.8\\n1hr 01min ago\\n19.15  N   155.48  W   33 2.0  ISLAND OF HAWAII, HAWAII',\n",
       " '2023-02-08   16:18:17.6\\n1hr 04min ago\\n38.00  N   37.51  E   5 2.8  CENTRAL TURKEY',\n",
       " 'F\\n2023-02-08   16:15:05.3\\n1hr 08min ago\\n37.55  N   37.34  E   14 2.9  CENTRAL TURKEY',\n",
       " '2023-02-08   16:12:04.2\\n1hr 11min ago\\n38.10  N   36.69  E   9 2.6  CENTRAL TURKEY',\n",
       " 'F\\n2023-02-08   16:01:57.0\\n1hr 21min ago\\n4.92  S   122.66  E   10 4.1  SULAWESI, INDONESIA',\n",
       " '2023-02-08   16:01:04.0\\n1hr 22min ago\\n38.15  N   38.61  E   2 2.9  EASTERN TURKEY',\n",
       " '2023-02-08   15:57:02.0\\n1hr 26min ago\\n5.69  S   154.36  E   117 5.0  BOUGAINVILLE REGION, P.N.G.',\n",
       " '1\\nIV\\n2023-02-08   15:56:50.9\\n1hr 26min ago\\n37.32  N   37.07  E   5 3.1  CENTRAL TURKEY',\n",
       " 'F\\n2023-02-08   15:51:45.0\\n1hr 31min ago\\n2.52  S   140.68  E   10 3.9  NEAR N COAST OF PAPUA, INDONESIA',\n",
       " '11\\nIII\\n2023-02-08   15:49:59.4\\n1hr 33min ago\\n37.84  N   36.61  E   5 4.3  CENTRAL TURKEY',\n",
       " '7\\nIII\\n2023-02-08   15:42:47.8\\n1hr 40min ago\\n37.05  N   36.63  E   11 3.2  CENTRAL TURKEY']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.TAG_NAME, 'tr')[14:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = [e.text for e in driver.find_elements(By.CLASS_NAME, 'tabev6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-02-08   17:12:52.5\\n10min ago',\n",
       " '2023-02-08   17:06:39.4\\n16min ago',\n",
       " '2023-02-08   17:03:58.4\\n19min ago',\n",
       " '2023-02-08   17:02:32.3\\n20min ago',\n",
       " '2023-02-08   17:01:12.6\\n21min ago',\n",
       " '2023-02-08   16:59:20.0\\n23min ago',\n",
       " '2023-02-08   16:55:39.5\\n27min ago',\n",
       " '2023-02-08   16:44:28.2\\n38min ago',\n",
       " '2023-02-08   16:40:33.2\\n42min ago',\n",
       " '2023-02-08   16:29:07.4\\n54min ago',\n",
       " '2023-02-08   16:21:19.8\\n1hr 01min ago',\n",
       " '2023-02-08   16:18:17.6\\n1hr 04min ago',\n",
       " '2023-02-08   16:15:05.3\\n1hr 08min ago',\n",
       " '2023-02-08   16:12:04.2\\n1hr 11min ago',\n",
       " '2023-02-08   16:01:57.0\\n1hr 21min ago',\n",
       " '2023-02-08   16:01:04.0\\n1hr 22min ago',\n",
       " '2023-02-08   15:57:02.0\\n1hr 26min ago',\n",
       " '2023-02-08   15:56:50.9\\n1hr 26min ago',\n",
       " '2023-02-08   15:51:45.0\\n1hr 31min ago',\n",
       " '2023-02-08   15:49:59.4\\n1hr 33min ago']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime = datetime[:20]\n",
    "datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38.09 '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CLASS_NAME, 'tabev1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = [f.find_elements(By.CLASS_NAME, 'tabev1')[0].text.strip() for f in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = [f.find_elements(By.CLASS_NAME, 'tabev1')[1].text.strip() for f in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [driver.find_elements(By.CLASS_NAME, 'tabev3')[i].text for i in range(len(rows))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CLASS_NAME, 'tabev2')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[e.text for e in driver.find_elements(By.CLASS_NAME, 'tabev2')]\n",
    "\n",
    "mag = data[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = mag[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [e.text for e in driver.find_elements(By.CLASS_NAME, 'tb_region')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = region[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = latitude[:-1]\n",
    "longitude = longitude[:-1]\n",
    "depth = depth[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "df[cols[0]] = datetime\n",
    "\n",
    "df[cols[1]] = latitude \n",
    "\n",
    "df[cols[2]] = longitude\n",
    "\n",
    "df[cols[3]] = depth\n",
    "\n",
    "df[cols[4]] = mag\n",
    "\n",
    "df[cols[5]] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date &amp; Time\\nUTC</th>\n",
       "      <th>Latitude\\ndegrees</th>\n",
       "      <th>Longitude\\ndegrees</th>\n",
       "      <th>Depth\\nkm</th>\n",
       "      <th>Mag\\n[+]</th>\n",
       "      <th>Region name\\n[+]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-08   17:12:52.5\\n10min ago</td>\n",
       "      <td>38.09</td>\n",
       "      <td>37.40</td>\n",
       "      <td>10</td>\n",
       "      <td>2.7</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-08   17:06:39.4\\n16min ago</td>\n",
       "      <td>38.87</td>\n",
       "      <td>37.38</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-08   17:03:58.4\\n19min ago</td>\n",
       "      <td>37.87</td>\n",
       "      <td>36.72</td>\n",
       "      <td>8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-08   17:02:32.3\\n20min ago</td>\n",
       "      <td>35.47</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-08   17:01:12.6\\n21min ago</td>\n",
       "      <td>38.09</td>\n",
       "      <td>37.17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-08   16:59:20.0\\n23min ago</td>\n",
       "      <td>37.10</td>\n",
       "      <td>36.74</td>\n",
       "      <td>11</td>\n",
       "      <td>3.5</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-08   16:55:39.5\\n27min ago</td>\n",
       "      <td>38.10</td>\n",
       "      <td>37.20</td>\n",
       "      <td>2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-08   16:44:28.2\\n38min ago</td>\n",
       "      <td>37.97</td>\n",
       "      <td>38.25</td>\n",
       "      <td>5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-02-08   16:40:33.2\\n42min ago</td>\n",
       "      <td>37.84</td>\n",
       "      <td>36.60</td>\n",
       "      <td>16</td>\n",
       "      <td>3.2</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-02-08   16:29:07.4\\n54min ago</td>\n",
       "      <td>37.74</td>\n",
       "      <td>37.40</td>\n",
       "      <td>17</td>\n",
       "      <td>2.7</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-02-08   16:21:19.8\\n1hr 01min ago</td>\n",
       "      <td>19.15</td>\n",
       "      <td>155.48</td>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-08   16:18:17.6\\n1hr 04min ago</td>\n",
       "      <td>38.00</td>\n",
       "      <td>37.51</td>\n",
       "      <td>5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-02-08   16:15:05.3\\n1hr 08min ago</td>\n",
       "      <td>37.55</td>\n",
       "      <td>37.34</td>\n",
       "      <td>14</td>\n",
       "      <td>2.9</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-02-08   16:12:04.2\\n1hr 11min ago</td>\n",
       "      <td>38.10</td>\n",
       "      <td>36.69</td>\n",
       "      <td>9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-02-08   16:01:57.0\\n1hr 21min ago</td>\n",
       "      <td>4.92</td>\n",
       "      <td>122.66</td>\n",
       "      <td>10</td>\n",
       "      <td>4.1</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-02-08   16:01:04.0\\n1hr 22min ago</td>\n",
       "      <td>38.15</td>\n",
       "      <td>38.61</td>\n",
       "      <td>2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-02-08   15:57:02.0\\n1hr 26min ago</td>\n",
       "      <td>5.69</td>\n",
       "      <td>154.36</td>\n",
       "      <td>117</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BOUGAINVILLE REGION, P.N.G.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-02-08   15:56:50.9\\n1hr 26min ago</td>\n",
       "      <td>37.32</td>\n",
       "      <td>37.07</td>\n",
       "      <td>5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-02-08   15:51:45.0\\n1hr 31min ago</td>\n",
       "      <td>2.52</td>\n",
       "      <td>140.68</td>\n",
       "      <td>10</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-02-08   15:49:59.4\\n1hr 33min ago</td>\n",
       "      <td>37.84</td>\n",
       "      <td>36.61</td>\n",
       "      <td>5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date & Time\\nUTC Latitude\\ndegrees  \\\n",
       "0       2023-02-08   17:12:52.5\\n10min ago             38.09   \n",
       "1       2023-02-08   17:06:39.4\\n16min ago             38.87   \n",
       "2       2023-02-08   17:03:58.4\\n19min ago             37.87   \n",
       "3       2023-02-08   17:02:32.3\\n20min ago             35.47   \n",
       "4       2023-02-08   17:01:12.6\\n21min ago             38.09   \n",
       "5       2023-02-08   16:59:20.0\\n23min ago             37.10   \n",
       "6       2023-02-08   16:55:39.5\\n27min ago             38.10   \n",
       "7       2023-02-08   16:44:28.2\\n38min ago             37.97   \n",
       "8       2023-02-08   16:40:33.2\\n42min ago             37.84   \n",
       "9       2023-02-08   16:29:07.4\\n54min ago             37.74   \n",
       "10  2023-02-08   16:21:19.8\\n1hr 01min ago             19.15   \n",
       "11  2023-02-08   16:18:17.6\\n1hr 04min ago             38.00   \n",
       "12  2023-02-08   16:15:05.3\\n1hr 08min ago             37.55   \n",
       "13  2023-02-08   16:12:04.2\\n1hr 11min ago             38.10   \n",
       "14  2023-02-08   16:01:57.0\\n1hr 21min ago              4.92   \n",
       "15  2023-02-08   16:01:04.0\\n1hr 22min ago             38.15   \n",
       "16  2023-02-08   15:57:02.0\\n1hr 26min ago              5.69   \n",
       "17  2023-02-08   15:56:50.9\\n1hr 26min ago             37.32   \n",
       "18  2023-02-08   15:51:45.0\\n1hr 31min ago              2.52   \n",
       "19  2023-02-08   15:49:59.4\\n1hr 33min ago             37.84   \n",
       "\n",
       "   Longitude\\ndegrees Depth\\nkm Mag\\n[+]                   Region name\\n[+]  \n",
       "0               37.40        10      2.7                     CENTRAL TURKEY  \n",
       "1               37.38         2      3.6                     CENTRAL TURKEY  \n",
       "2               36.72         8      2.9                     CENTRAL TURKEY  \n",
       "3                3.66         4      2.4                STRAIT OF GIBRALTAR  \n",
       "4               37.17         8      3.1                     CENTRAL TURKEY  \n",
       "5               36.74        11      3.5                     CENTRAL TURKEY  \n",
       "6               37.20         2      4.2                     CENTRAL TURKEY  \n",
       "7               38.25         5      2.7                     EASTERN TURKEY  \n",
       "8               36.60        16      3.2                     CENTRAL TURKEY  \n",
       "9               37.40        17      2.7                     CENTRAL TURKEY  \n",
       "10             155.48        33      2.0           ISLAND OF HAWAII, HAWAII  \n",
       "11              37.51         5      2.8                     CENTRAL TURKEY  \n",
       "12              37.34        14      2.9                     CENTRAL TURKEY  \n",
       "13              36.69         9      2.6                     CENTRAL TURKEY  \n",
       "14             122.66        10      4.1                SULAWESI, INDONESIA  \n",
       "15              38.61         2      2.9                     EASTERN TURKEY  \n",
       "16             154.36       117      5.0        BOUGAINVILLE REGION, P.N.G.  \n",
       "17              37.07         5      3.1                     CENTRAL TURKEY  \n",
       "18             140.68        10      3.9   NEAR N COAST OF PAPUA, INDONESIA  \n",
       "19              36.61         5      4.3                     CENTRAL TURKEY  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url11 = 'https://twitter.com/ManuelZerpadl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.7K Tweets'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '//div[@dir=\"ltr\"]')[8].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url11 = 'https://twitter.com/ManuelZerpadl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'694'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '//span[@class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\"]')[14].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url8 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = driver.find_elements(By.XPATH, '//strong')[1:11]\n",
    "len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts = driver.find_elements(By.XPATH, '//small')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for e in langs:\n",
    "    keys.append(e.text)\n",
    "    \n",
    "values = []\n",
    "for e in arts: \n",
    "    values.append(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English': '6 606 000+ articles',\n",
       " 'Русский': '1 887 000+ статей',\n",
       " '日本語': '1 359 000+ 記事',\n",
       " 'Deutsch': '2 764 000+ Artikel',\n",
       " 'Français': '2 488 000+ articles',\n",
       " 'Español': '1 833 000+ artículos',\n",
       " 'Italiano': '1 792 000+ voci',\n",
       " '中文': '1 331 000+ 条目 / 條目',\n",
       " 'فارسی': '947 000+ مقاله',\n",
       " 'Polski': '1 552 000+ haseł'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccio = dict(zip(keys, values))\n",
    "diccio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url9 = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h3 class=\"govuk-heading-s dgu-topics__heading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = driver.find_elements(By.XPATH, '//h3[@class=\"govuk-heading-s dgu-topics__heading\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_ds = []\n",
    "for e in datasets:\n",
    "    lst_ds.append(e.text)\n",
    "\n",
    "lst_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url10 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_raw = driver.find_elements(By.XPATH, '//th[@class=\"headerSort\"]')[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language', 'Native speakers\\n(millions)', 'Language family', 'Branch']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [e.text for e in cols_raw]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_rows = driver.find_elements(By.XPATH, '//a[@class=\"mw-redirect\"]')[7:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandarin Chinese',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'Bengali',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Yue Chinese',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = [e.text for e in lan_rows]\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'475'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '//td')[1].text\n",
    "driver.find_elements(By.XPATH, '//td')[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_rows = driver.find_elements(By.XPATH, '//td')[1:38:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['920', '475', '373', '344', '234', '232', '154', '125', '85.2', '84.6']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = [e.text for e in ns_rows]\n",
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_rows = driver.find_elements(By.XPATH, '//td')[2:39:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sino-Tibetan',\n",
       " 'Indo-European',\n",
       " 'Indo-European',\n",
       " 'Indo-European',\n",
       " 'Indo-European',\n",
       " 'Indo-European',\n",
       " 'Indo-European',\n",
       " 'Japonic',\n",
       " 'Sino-Tibetan',\n",
       " 'Austroasiatic']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = [e for e in lf_rows]\n",
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "bran_rows = driver.find_elements(By.XPATH, '//td')[3:40:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sinitic',\n",
       " 'Romance',\n",
       " 'Germanic',\n",
       " 'Indo-Aryan',\n",
       " 'Indo-Aryan',\n",
       " 'Romance',\n",
       " 'Balto-Slavic',\n",
       " 'Japanese',\n",
       " 'Sinitic',\n",
       " 'Vietic']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bran = [e.text for e in bran_rows]\n",
    "bran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native speakers\\n(millions)</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Language, Native speakers\n",
       "(millions), Language family, Branch]\n",
       "Index: []"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Language = langs\n",
    "df['Native speakers\\n(millions)'] = ns\n",
    "df['Language family'] = lf\n",
    "df.Branch = bran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native speakers\\n(millions)</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>920</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>475</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>373</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>344</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>232</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>154</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>125</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>85.2</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>84.6</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Language Native speakers\\n(millions) Language family        Branch\n",
       "0  Mandarin Chinese                         920    Sino-Tibetan       Sinitic\n",
       "1           Spanish                         475   Indo-European       Romance\n",
       "2           English                         373   Indo-European      Germanic\n",
       "3             Hindi                         344   Indo-European    Indo-Aryan\n",
       "4           Bengali                         234   Indo-European    Indo-Aryan\n",
       "5        Portuguese                         232   Indo-European       Romance\n",
       "6           Russian                         154   Indo-European  Balto-Slavic\n",
       "7          Japanese                         125         Japonic      Japanese\n",
       "8       Yue Chinese                        85.2    Sino-Tibetan       Sinitic\n",
       "9        Vietnamese                        84.6   Austroasiatic        Vietic"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url11 = 'https://twitter.com/ManuelZerpadl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Será que estoy feliz tan temprano porque ya lloré?'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH,'//span[@class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\"]')[23].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bebo se puso futbolero y me llenó el tl de puro intenso'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH,'//span[@class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\"]')[30].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = driver.find_elements(By.XPATH,'//span[@class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\"]')[23:43:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Será que estoy feliz tan temprano porque ya lloré?',\n",
       " 'Bebo se puso futbolero y me llenó el tl de puro intenso',\n",
       " 'Encontré tu pintura de uñas']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.text for e in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url12 = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Movie', 'Release', 'Director', 'Stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The Shawshank Redemption (1994)'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '//td[@class=\"titleColumn\"]')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "pelis = [\" \".join(driver.find_elements(By.XPATH, '//td[@class=\"titleColumn\"]')[i].text.split()[1:-1]) for i in range(len(driver.find_elements(By.XPATH, '//td[@class=\"titleColumn\"]')[:20]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption',\n",
       " 'The Godfather',\n",
       " 'The Dark Knight',\n",
       " 'The Godfather Part II',\n",
       " '12 Angry Men',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Pulp Fiction',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'The Good, the Bad and the Ugly',\n",
       " 'Forrest Gump',\n",
       " 'Fight Club',\n",
       " 'The Lord of the Rings: The Two Towers',\n",
       " 'Inception',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'The Matrix',\n",
       " 'Goodfellas',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Se7en',\n",
       " 'Seven Samurai']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_years = driver.find_elements(By.XPATH, '//span[@class=\"secondaryInfo\"]')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(2001)',\n",
       " '(1966)',\n",
       " '(1994)',\n",
       " '(1999)',\n",
       " '(2002)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1975)',\n",
       " '(1995)',\n",
       " '(1954)']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = [e.text for e in re_years]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_ = driver.find_elements(By.XPATH, '//strong')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = [e.text for e in stars_]\n",
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = driver.find_elements(By.XPATH, '//td[@class=\"titleColumn\"]//a')[:20] #.get_attribute(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frank', 'Darabont']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs[0].get_attribute('title').split()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "dires = [\" \".join(dirs[i].get_attribute('title').split()[:2]) for i in range(len(dirs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frank Darabont',\n",
       " 'Francis Ford',\n",
       " 'Christopher Nolan',\n",
       " 'Francis Ford',\n",
       " 'Sidney Lumet',\n",
       " 'Steven Spielberg',\n",
       " 'Peter Jackson',\n",
       " 'Quentin Tarantino',\n",
       " 'Peter Jackson',\n",
       " 'Sergio Leone',\n",
       " 'Robert Zemeckis',\n",
       " 'David Fincher',\n",
       " 'Peter Jackson',\n",
       " 'Christopher Nolan',\n",
       " 'Irvin Kershner',\n",
       " 'Lana Wachowski',\n",
       " 'Martin Scorsese',\n",
       " 'Milos Forman',\n",
       " 'David Fincher',\n",
       " 'Akira Kurosawa']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release</th>\n",
       "      <th>Director</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>Francis Ford</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>Francis Ford</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Good, the Bad and the Ugly</td>\n",
       "      <td>(1966)</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>(1999)</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inception</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>(1980)</td>\n",
       "      <td>Irvin Kershner</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>(1999)</td>\n",
       "      <td>Lana Wachowski</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Goodfellas</td>\n",
       "      <td>(1990)</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>(1975)</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>(1954)</td>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Movie Release  \\\n",
       "0                            The Shawshank Redemption  (1994)   \n",
       "1                                       The Godfather  (1972)   \n",
       "2                                     The Dark Knight  (2008)   \n",
       "3                               The Godfather Part II  (1974)   \n",
       "4                                        12 Angry Men  (1957)   \n",
       "5                                    Schindler's List  (1993)   \n",
       "6       The Lord of the Rings: The Return of the King  (2003)   \n",
       "7                                        Pulp Fiction  (1994)   \n",
       "8   The Lord of the Rings: The Fellowship of the Ring  (2001)   \n",
       "9                      The Good, the Bad and the Ugly  (1966)   \n",
       "10                                       Forrest Gump  (1994)   \n",
       "11                                         Fight Club  (1999)   \n",
       "12              The Lord of the Rings: The Two Towers  (2002)   \n",
       "13                                          Inception  (2010)   \n",
       "14     Star Wars: Episode V - The Empire Strikes Back  (1980)   \n",
       "15                                         The Matrix  (1999)   \n",
       "16                                         Goodfellas  (1990)   \n",
       "17                    One Flew Over the Cuckoo's Nest  (1975)   \n",
       "18                                              Se7en  (1995)   \n",
       "19                                      Seven Samurai  (1954)   \n",
       "\n",
       "             Director Stars  \n",
       "0      Frank Darabont   9.2  \n",
       "1        Francis Ford   9.2  \n",
       "2   Christopher Nolan   9.0  \n",
       "3        Francis Ford   9.0  \n",
       "4        Sidney Lumet   9.0  \n",
       "5    Steven Spielberg   8.9  \n",
       "6       Peter Jackson   8.9  \n",
       "7   Quentin Tarantino   8.8  \n",
       "8       Peter Jackson   8.8  \n",
       "9        Sergio Leone   8.8  \n",
       "10    Robert Zemeckis   8.8  \n",
       "11      David Fincher   8.7  \n",
       "12      Peter Jackson   8.7  \n",
       "13  Christopher Nolan   8.7  \n",
       "14     Irvin Kershner   8.7  \n",
       "15     Lana Wachowski   8.7  \n",
       "16    Martin Scorsese   8.7  \n",
       "17       Milos Forman   8.6  \n",
       "18      David Fincher   8.6  \n",
       "19     Akira Kurosawa   8.6  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "df.Movie = pelis\n",
    "df.Release = year\n",
    "df.Director = dires\n",
    "df.Stars = stars\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
